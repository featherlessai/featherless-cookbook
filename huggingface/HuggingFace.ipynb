{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f6f474c-cc1a-42d2-8c02-2070531a1590",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Featherless AI on Hugging Face Inference Providers ðŸ”¥\n",
    "\n",
    "Featherless AI is now a supported Inference Provider on the Hugging Face Hub! This integration allows you to access a wide variety of text and conversational models through Hugging Face's infrastructure, including the latest open-source models from:\n",
    "\n",
    "- DeepSeek\n",
    "- Meta\n",
    "- Google\n",
    "- Qwen\n",
    "- And many more!\n",
    "\n",
    "## Key Benefits\n",
    "\n",
    "- **Serverless AI Inference**: No need to manage servers or infrastructure\n",
    "- **Large Model Catalog**: Access to an extensive range of models\n",
    "- **Cost-Effective**: Serverless pricing with pay-as-you-go model\n",
    "- **Easy Integration**: Seamless integration with Hugging Face's client SDKs (Python & JavaScript)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727519d4-582c-4f4d-967e-a9b646676e95",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Getting Started\n",
    "\n",
    "First, ensure you have the latest version of `huggingface_hub` installed:\n",
    "```bash\n",
    "pip install --upgrade huggingface-hub>=0.33.0\n",
    "```\n",
    "\n",
    "### Authentication Options\n",
    "\n",
    "1. **Using Hugging Face Token** (Recommended for getting started)\n",
    "   - Requests are routed through Hugging Face\n",
    "   - Charges applied to your HF account\n",
    "   - Free tier available for signed-in users\n",
    "   - PRO users get $2 worth of Inference credits monthly\n",
    "\n",
    "2. **Using Featherless AI API Key**\n",
    "   - Direct requests to Featherless AI\n",
    "   - Billing handled through your Featherless AI account\n",
    "   - Set up your API key in HF user account settings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a8b340-c8ac-41fc-b951-838d0bb517cc",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Example: Using DeepSeek-R1 Model\n",
    "\n",
    "Below is a simple example showing how to use the DeepSeek-R1 model through Featherless AI. The code demonstrates:\n",
    "\n",
    "1. Creating an `InferenceClient` with Featherless AI as the provider\n",
    "2. Sending a chat completion request to the DeepSeek-R1 model\n",
    "3. Processing the response\n",
    "\n",
    "Note: Make sure to set your HF_TOKEN environment variable or replace it with your actual token.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "966ca159-d9fa-47fb-b57e-89e93bf5493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface_hub>=0.33.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dd8056d-5eeb-4eea-a926-4c1f82ce6c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionOutputMessage(role='assistant', content='<think>\\nOkay, the user asked, \"What is the capital of France?\" That seems straightforward. They\\'re likely looking for a quick answer, but maybe they need a bit more context too.  \\n\\nFirst, I should confirm the answer is Parisâ€”that\\'s basic geography. But why ask this? Maybe they\\'re a student doing homework, a traveler planning a trip, or someone verifying trivia. The question is simple, but providing extra details could be helpful.  \\n\\nI\\'ll mention Paris and add that it\\'s the largest city in France, along with some key attractions like the Eiffel Tower and Louvre. That might address unspoken curiosity about why Paris matters. If they wanted just the name, the extras won\\'t hurt; if they needed more, itâ€™s there.  \\n\\nAlso, the tone should stay friendly and encouraging. Ending with \"Let me know if you have other questions!\" leaves the door openâ€”they might be testing my reliability or have follow-ups about France.  \\n\\nNo signs of confusion or urgency in the query, so a calm, clear response fits. Keeping it concise but informative feels right.\\n</think>\\nThe capital of France is **Paris**.  \\n\\nParis is not only the political center of France but also its largest city and a global hub for art, fashion, gastronomy, and culture. Famous landmarks include the **Eiffel Tower**, **Louvre Museum**, **Notre-Dame Cathedral**, and the **Champs-Ã‰lysÃ©es**.  \\n\\nLet me know if you\\'d like more details! ðŸ˜Š', tool_call_id=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "client = InferenceClient(\n",
    "    provider=\"featherless-ai\",\n",
    "    api_key=os.environ[\"HF_TOKEN\"],\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"deepseek-ai/DeepSeek-R1-0528\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the capital of France?\"\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d337f459-d071-4c90-a881-dd6f60b61a18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
