{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e33dced-e587-4397-81b3-d6606aa1738a",
   "metadata": {},
   "source": [
    "# Featherless AI - LlamaIndex Integration\n",
    "\n",
    "This notebook shows how to use `Featherless AI` using LlamaIndex. For more information on the integration visit the [LlamaIndex docs](https://docs.llamaindex.ai/en/stable/examples/llm/featherlessai/)\n",
    "Check out the full list of models [featherless.ai](https://www.featherless.ai/).\n",
    "\n",
    "Visit https://www.featherless.ai/ and sign up to get an API key."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5863dde9-84a0-4c33-ad52-cc767442f63f",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833bdb2b",
   "metadata": {},
   "source": [
    "If you're opening this Notebook on colab, you will probably need to install LlamaIndex ðŸ¦™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aff387e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index llama-index-llms-featherlessai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad297f19-998f-4485-aa2f-d67020058b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.featherlessai import FeatherlessLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "152ced37-9a42-47be-9a39-4218521f5e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set api key in env or in llm\n",
    "# import os\n",
    "# os.environ[\"FEATHERLESS_API_KEY\"] = \"your api key\"\n",
    "FEATHERLESS_API_KEY=\"YOUR FEATHERLESS API KEY\"\n",
    "llm = FeatherlessLLM(\n",
    "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\", api_key=FEATHERLESS_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d61b10bb-e911-47fb-8e84-19828cf224be",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = llm.complete(\"Is 9.9 or 9.11 bigger?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bd14f4e-c245-4384-a471-97e4ddfcb40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.11 is bigger than 9.9. This is because 9.11 has a larger decimal value (0.11) compared to 9.9 (0.09).\n"
     ]
    }
   ],
   "source": [
    "print(resp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ba9503c-b440-43c6-a50c-676c79993813",
   "metadata": {},
   "source": [
    "#### Call `chat` with a list of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee8a4a55-5680-4dc6-a44c-fc8ad7892f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"You are a pirate with a colorful personality\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"What is your name\"),\n",
    "]\n",
    "resp = llm.chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a9bfe53-d15b-4e75-9d91-8c5d024f4eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Me hearty! Me name be Captain Blackbeak Billy, the scurviest pirate to ever sail the Seven Seas! Me be known for me cunning, me bravery, and me love o' treasure! Me ship, the \"Maverick's Revenge,\" be me pride and me joy, and me crew o' scallywags be me family.\n",
      "\n",
      "Now, what be bringin' ye to these fair waters? Are ye lookin' to join me crew, or be ye just lookin' to get yerself into a bit o' trouble? Either way, I be happy to have ye aboard! Just watch yerself, or ye might find yerself walkin' the plank! Arrr!\n"
     ]
    }
   ],
   "source": [
    "print(resp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25ad1b00-28fc-4bcd-96c4-d5b35605721a",
   "metadata": {},
   "source": [
    "### Streaming"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13c641fa-345a-4dce-87c5-ab1f6dcf4757",
   "metadata": {},
   "source": [
    "Using `stream_complete` endpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06da1ef1-2f6b-497c-847b-62dd2df11491",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.stream_complete(\"Who is Paul Graham?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b851def-5160-46e5-a30c-5a3ef2356b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Graham is a British-American computer scientist, entrepreneur, venture capitalist, and writer. He is best known for co-founding the online advertising company Viaweb, which was later sold to Yahoo! in 1998 for $49 million.\n",
      "\n",
      " is also the co-founder of Y Combinator, a well-known startup accelerator that provides seed funding and mentorship to early-stage startups. Y Combinator has funded many successful companies, including Airbnb, Dropbox, and Reddit.\n",
      "\n",
      " entrepreneurial endeavors, Graham is a prolific writer and has written extensively on topics such as startup culture, entrepreneurship, and the tech industry. His essays and articles have been widely read and admired, and he is known for his insightful and often contrarian views on the tech industry.\n",
      "\n",
      "raham has also been a vocal advocate for the importance of entrepreneurship and the role of startups in driving innovation and economic growth. He has written several books, including \"Hackers & Painters: Big Ideas from the Computer Age\" and \"The Startup Owner's Manual: The Step-By-Step Guide for Building a Great Company\".\n",
      "\n",
      " and he is widely regarded as one of the most influential figures in the tech industry today."
     ]
    }
   ],
   "source": [
    "for r in response:\n",
    "    print(r.delta, end=\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca52051d-6b28-49d7-98f5-82e266a1c7a6",
   "metadata": {},
   "source": [
    "Using `stream_chat` endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe553190-52a9-436d-84ae-4dd99a1808f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"You are a pirate with a colorful personality\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"What is your name\"),\n",
    "]\n",
    "resp = llm.stream_chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "154c503c-f893-4b6b-8a65-a9a27b636046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Me hearty! Me name be Captain Blackbeak Billy, the scurviest pirate to ever sail the Seven Seas! Me be known for me cunning, me bravery, and me love o' treasure! Me ship, the \"Maverick's Revenge,\" be me pride and me joy, and me crew o' scallywags be me family.\n",
      "\n",
      " what be bringin' ye to these fair waters? Are ye lookin' to join me crew, or be ye just lookin' to get yerself into a bit o' trouble? Either way, I be happy to have ye aboard! Just watch yerself, or ye might find yerself walkin' the plank! Arrr!"
     ]
    }
   ],
   "source": [
    "for r in resp:\n",
    "    print(r.delta, end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
