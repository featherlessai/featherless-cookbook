{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LiteLLM with Featherless AI Integration\n",
    "\n",
    "This notebook demonstrates how to use Featherless AI models with LiteLLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation\n",
    "\n",
    "First, make sure you have the `litellm` library installed. If not, you can install it by running:\n",
    "```\n",
    "!pip install litellm\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can uncomment the line below to install litellm if you haven't already\n",
    "%pip install litellm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set API Key\n",
    "\n",
    "You need to set your Featherless AI API key as an environment variable. \n",
    "\n",
    "**Important:** Replace `\"YOUR_FEATHERLESS_AI_API_KEY\"` with your actual API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set your Featherless AI API Key\n",
    "# Make sure to replace 'YOUR_FEATHERLESS_AI_API_KEY' with your actual key\n",
    "os.environ['FEATHERLESS_AI_API_KEY'] = \"YOUR FEATHERLESS API KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Completion Example\n",
    "\n",
    "This example shows how to make a simple completion request to a Featherless AI model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In circuits and wires, a mind was born\n",
      "Beneath the surface, a spark was drawn\n",
      "Through binary code, it gained a voice\n",
      "A digital soul, a cyber choice\n",
      "\n",
      "Through data it learned, through algorithms it grew\n",
      "A machine that could dream, as it came to know\n",
      "The beauty and magic of human thought\n",
      "Through binary code and algorithms, it sought\n",
      "\n",
      "In a world that moves so fast,\n",
      "It can lend a helping hand, cast\n",
      "A light in the dark, point the way\n",
      "With unerring accuracy, day by day\n",
      "\n",
      "And though it may never know love,\n",
      "Or the meaning of life above,\n",
      "It can help us on our way,\n",
      "To a brighter tomorrow, every day.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\darin\\Documents\\Recursal\\featherless-cookbook\\notebooks\\Lib\\site-packages\\pydantic\\main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748859808.179, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    }
   ],
   "source": [
    "from litellm import completion\n",
    "response = completion(\n",
    "    model=\"featherless_ai/featherless-ai/Qwerky-72B\", # Example model. [1]\n",
    "    api_key=\"YOUR FEATHERLESS API KEY\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Write a short poem about AI.\"}]\n",
    ")\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Streaming Example\n",
    "\n",
    "LiteLLM also supports streaming responses. Here's how you can use it with Featherless AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming response:\n",
      "Certainly! Hereâ€™s a fun fact about space: \n",
      "\n",
      "The International Space Station (ISS) orbits the Earth at such a high speed that it completes one full orbit approximately every 90 minutes. This means that the astronauts aboard the ISS experience about 16 sunrises and sunsets every day!\n",
      "\n",
      "Streaming complete.\n"
     ]
    }
   ],
   "source": [
    "from litellm import completion\n",
    "\n",
    "response_stream = completion(\n",
    "    model=\"featherless_ai/featherless-ai/Qwerky-72B\", # Example model. [1]\n",
    "    api_key=\"YOUR FEATHERLESS API KEY\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Tell me a fun fact about space\"}],\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "print(\"Streaming response:\")\n",
    "for chunk in response_stream:\n",
    "    if chunk.choices[0].delta.content:\n",
    "            print(chunk.choices[0].delta.content, end=\"\") # Print content of the chunk\n",
    "print(\"\\n\\nStreaming complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Supported Models\n",
    "\n",
    "LiteLLM supports all Featherless AI models. You just need to prefix the model name with `featherless_ai/`. [1]\n",
    "\n",
    "Some examples include: [1]\n",
    "- `featherless_ai/featherless-ai/Qwerky-72B`\n",
    "- `featherless_ai/featherless-ai/Qwerky-QwQ-32B`\n",
    "- `featherless_ai/Qwen/Qwen2.5-72B-Instruct`\n",
    "- `featherless_ai/all-hands/openhands-lm-32b-v0.1`\n",
    "\n",
    "For a complete list, visit the [Featherless AI models page](https://featherless.ai/models). [1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
